import streamlit as st
import PyPDF2
import nltk
nltk.download("punkt")  # âœ… make sure this is here!
from nltk.tokenize import sent_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ğŸ§  Download tokenizer only once
nltk.download('punkt')

# ğŸ“„ Function to extract text from PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# ğŸ“– Load and process the handbook
handbook_text = extract_text_from_pdf("Kepler_college_Student_Handbook.pdf")
sentences = sent_tokenize(handbook_text)

# ğŸ” Convert sentences to TF-IDF vectors
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(sentences)


# ğŸ›ï¸ Streamlit UI
st.title("ğŸ“ Emely's Chatbot")
st.write("Ask me anything about the Kepler Student handbook!")

# ğŸ“¥ Input from the user
user_question = st.text_input("Your question:")

# ğŸ§  If there's a question, process it
if user_question:
    question_vector = vectorizer.transform([user_question])
    similarities = cosine_similarity(question_vector, tfidf_matrix)
    best_match_index = similarities.argmax()
    answer = sentences[best_match_index]

    # ğŸ“¤ Show result
    st.subheader("Answer:")
    st.write(answer)
